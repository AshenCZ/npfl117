# Deep Learning Seminar, Summer 2018/19

## Tab: Home

In recent years, **deep neural networks** have been used to solve complex
machine-learning problems and have achieved significant **state-of-the-art**
results in **many** areas. The whole field of deep learning has been developing
**rapidly**, with **new methods** and **techniques** emerging steadily.

The goal of the seminar is to follow the **newest advancements** in the deep
learning field. The course takes form of a **reading group** – each lecture
a paper is presented by one of the students. The paper is announced in advance,
hence all participants can read it beforehand and can take part in the
**discussion of the paper**.

If you want to receive announcements about chosen paper, sign up to our
[mailing list ufal-rg@googlegroups.com](https://groups.google.com/forum/#!forum/ufal-rg).

### About

SIS code: [NPFL117](https://is.cuni.cz/studium/eng/predmety/index.php?do=predmet&kod=NPFL117)<br>
Semester: winter + summer<br>
E-credits: 3<br>
Examination: 0/2 C<br>
Guarantor: [Milan Straka](https://ufal.mff.cuni.cz/milan-straka)

### Timespace Coordinates

The Deep Learning Seminar takes place on **Tuesday** at **10:40** in **S8**. We will first meet on Tuesday **Mar 05**.

### Requirements

To pass the course, you need to **present a research paper** and sufficiently
attend the presentations.

## Tab: Program

If you want to receive announcements about chosen paper, sign up to our
[mailing list ufal-rg@googlegroups.com](https://groups.google.com/forum/#!forum/ufal-rg).

To add your name to a paper the table below, edit the
[source code on GitHub](https://github.com/ufal/npfl117/edit/master/1819-summer/README.md) and send a PR.

<div class="program"><style>
  .program td { vertical-align: middle !important}
  .program tr>td:nth-of-type(1), .program tr>td:nth-of-type(2) {white-space: nowrap}
</style>

| Date        | Who                | Topic | Paper(s)
| ----        | ---                | ----- | --------
| 05 Mar 2019 | Milan Straka       | Optimization | Noam Shazeer, Mitchell Stern: **[Adafactor: Adaptive Learning Rates with Sublinear Memory Cost](https://arxiv.org/abs/1804.04235)**<br>Ilya Loshchilov, Frank Hutter: **[Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)**<br>Sashank J. Reddi, Satyen Kale, Sanjiv Kumar: **[On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)**<br>Liangchen Luo, Yuanhao Xiong, Yan Liu, Xu Sun: **[Adaptive Gradient Methods with Dynamic Bound of Learning Rate](https://openreview.net/forum?id=Bkg3g2R9FX)**
|*12 Mar 2019*|*No DL Seminar*     |              |
| 19 Mar 2019 |                    |              |
| 26 Mar 2019 |                    |              |
| 02 Apr 2019 |                    |              |
| 09 Apr 2019 |                    |              |
| 16 Apr 2019 |                    |              |
| 23 Apr 2019 |                    |              |
| 30 Apr 2019 |                    |              |
| 07 May 2019 |                    |              |
|*14 May 2019*|*No DL Seminar*     |              | *Rector's Day*
| 21 May 2019 |                    |              |


- Sam McCandlish, Jared Kaplan, Dario Amodei, OpenAI Dota Team: **An Empirical Model of Large-Batch Training**.  https://arxiv.org/abs/1812.06162

- Jesse Farebrother, Marlos C. Machado, Michael Bowling: **Generalization and Regularization in DQN**.  https://arxiv.org/abs/1810.00123
- Karl Cobbe, Oleg Klimov, Chris Hesse, Taehoon Kim, John Schulman: **Quantifying Generalization in Reinforcement Learning**.  https://arxiv.org/abs/1812.02341

- Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean: **Efficient Neural Architecture Search via Parameter Sharing**.  https://arxiv.org/abs/1802.03268
- Hanxiao Liu, Karen Simonyan, Yiming Yang: **DARTS: Differentiable Architecture Search**.  https://arxiv.org/abs/1806.09055

- David R. So, Chen Liang, Quoc V. Le: **The Evolved Transformer**.  https://arxiv.org/abs/1901.11117
- Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov: **Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context**.  https://arxiv.org/abs/1901.02860

- Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár: **Focal Loss for Dense Object Detection**.  https://arxiv.org/abs/1708.02002
- Xuebo Liu, Ding Liang, Shi Yan, Dagui Chen, Yu Qiao, Junjie Yan: **FOTS: Fast Oriented Text Spotting with a Unified Network**.  https://arxiv.org/abs/1801.01671

- James Martens, Roger Grosse: **Optimizing Neural Networks with Kronecker-factored Approximate Curvature**.  https://arxiv.org/abs/1503.05671
- Roger Grosse, James Martens: **A Kronecker-factored approximate Fisher matrix for convolution layers**.  https://arxiv.org/abs/1602.01407
- Jimmy Ba, Roger Grosse, James Martens: **Distributed Second-Order Optimization using Kronecker-Factored Approximations**. https://jimmylba.github.io/papers/nsync.pdf
- James Martens, Jimmy Ba: **Kronecker-Factored Curvature Approximations for Recurrent Neural Networks**. https://openreview.net/pdf?id=HyMTkQZAb
- Thomas George, César Laurent, Xavier Bouthillier, Nicolas Ballas, Pascal Vincent: **Fast Approximate Natural Gradient Descent in a Kronecker-factored Eigenbasis**.  https://arxiv.org/abs/1806.03884

- Leslie N. Smith: **Cyclical Learning Rates for Training Neural Networks**.  https://arxiv.org/abs/1506.01186
- Ilya Loshchilov, Frank Hutter: **SGDR: Stochastic Gradient Descent with Warm Restarts**.  https://arxiv.org/abs/1608.03983

- Jose A. Arjona-Medina, Michael Gillhofer, Michael Widrich, Thomas Unterthiner, Johannes Brandstetter, Sepp Hochreiter: **RUDDER: Return Decomposition for Delayed Rewards**.  https://arxiv.org/abs/1806.07857

- Zhuora Yang, Yuchen Xie, Zhaoran Wang: **A Theoretical Analysis of Deep Q-Learning**.  https://arxiv.org/abs/1901.00137
- Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat, Karl Tuyls, Remi Munos, Michael Bowling: **Actor-Critic Policy Optimization in Partially Observable Multiagent Environments**.  https://arxiv.org/abs/1810.09026

- Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, James Davidson: **Learning Latent Dynamics for Planning from Pixels**.  https://arxiv.org/abs/1811.04551 https://planetrl.github.io/

- spectral věci

- global convergence

- RL planning
- Hao-Tien Lewis Chiang, Aleksandra Faust, Marek Fiser, Anthony Francis: **Learning Navigation Behaviors End-to-End with AutoRL**.  https://arxiv.org/abs/1809.10124
- Anthony Francis, Aleksandra Faust, Hao-Tien Lewis Chiang, Jasmine Hsu, J. Chase Kew, Marek Fiser, Tsang-Wei Edward Lee: **Long-Range Indoor Navigation with PRM-RL**.  https://arxiv.org/abs/1902.09458


## Tab: Related Courses

### Related Coursed

#### [Deep Learning](https://ufal.mff.cuni.cz/courses/npfl114)
Course introducing deep neural networks, from the basics to the latest advances,
focusing both on **theory** as well as on **practical aspects**.

#### [Deep Reinforcement Learning](https://ufal.mff.cuni.cz/courses/npfl122)
Course introducing reinforcement learning, from basic tabular methods to
involvement of deep neural networks, focusing both on **theory** as well as on
**practical aspects**.

#### [ÚFAL Reading Group](https://ufal.mff.cuni.cz/courses/rg)
Previously, Deep Learning Seminar was held unofficially as ÚFAL Reading Group,
you can see the discussed paper here:
- [ÚFAL Reading Group 2016](https://ufal.mff.cuni.cz/courses/rg/2016)
- [ÚFAL Reading Group 2015](https://ufal.mff.cuni.cz/courses/rg/2015)
- [ÚFAL Reading Group 2014](https://ufal.mff.cuni.cz/courses/rg/2014)

## Tab: Archive

### Archive

#### [Deep Learning Seminar, Winter 2018/19](https://ufal.mff.cuni.cz/courses/npfl117/1819-winter)

#### [Deep Learning Seminar, Summer 2017/18](https://ufal.mff.cuni.cz/courses/npfl117/1718-summer)

#### [Deep Learning Seminar, Summer 2016/17](https://ufal.mff.cuni.cz/courses/npfl117/1617-summer)
